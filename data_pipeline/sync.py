"""
ë°ì´í„° ë™ê¸°í™” ì‹œìŠ¤í…œ

ë°ì´í„° ë³€ê²½ ì‹œ ê´€ë ¨ í…Œì´ë¸”ë“¤ì„ ìë™ìœ¼ë¡œ ë™ê¸°í™”
CLAUDE.md ì œ1ì›ì¹™: ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì—°ê²° (DATA PIPELINE INTEGRITY)
"""

from typing import Dict, Any, List, Optional, Set
from datetime import datetime
from loguru import logger
from enum import Enum


class SyncAction(str, Enum):
    """ë™ê¸°í™” ì•¡ì…˜"""
    UPDATE = "update"
    DELETE = "delete"
    INVALIDATE_CACHE = "invalidate_cache"
    RECALCULATE = "recalculate"


class DataSynchronizer:
    """
    ë°ì´í„° ë™ê¸°í™” ê´€ë¦¬ì
    
    í•µì‹¬ ê·œì¹™:
    - ë‹¨ì¼ ì§„ì‹¤ ì›ì²œ (Single Source of Truth)
    - íŒŒì´í”„ë¼ì¸ ì „íŒŒ (Propagation)
    - ë°ì´í„° ë¬´ê²°ì„± (Integrity)
    """
    
    # ë°ì´í„° ì˜ì¡´ì„± ê·¸ë˜í”„
    # key: ì†ŒìŠ¤ í…Œì´ë¸”, value: ì˜ì¡´í•˜ëŠ” í…Œì´ë¸”ë“¤ê³¼ ë™ê¸°í™” ì•¡ì…˜
    DEPENDENCY_GRAPH = {
        "players": [
            ("members", "player_id", SyncAction.UPDATE),
            ("matches", "player1_id", SyncAction.UPDATE),
            ("matches", "player2_id", SyncAction.UPDATE),
            ("matches", "winner_id", SyncAction.UPDATE),
            ("rankings", "player_id", SyncAction.UPDATE),
            ("player_rankings", "player_id", SyncAction.UPDATE),
        ],
        "events": [
            ("matches", "event_id", SyncAction.UPDATE),
            ("rankings", "event_id", SyncAction.UPDATE),
            ("pool_results", "event_id", SyncAction.UPDATE),
            ("tournament_results", "event_id", SyncAction.UPDATE),
        ],
        "competitions": [
            ("events", "competition_id", SyncAction.UPDATE),
        ],
    }
    
    # ìºì‹œ ë¬´íš¨í™” ëŒ€ìƒ
    CACHE_INVALIDATION_MAP = {
        "players": ["player_profile", "player_stats", "team_roster"],
        "matches": ["player_profile", "event_results", "head_to_head"],
        "events": ["competition_detail", "event_results"],
        "competitions": ["competition_list", "competition_detail"],
        "rankings": ["player_profile", "event_results", "rankings_page"],
    }
    
    def __init__(self, db_client=None):
        self.db = db_client
        self._sync_log: List[Dict[str, Any]] = []
        self._pending_syncs: Set[str] = set()
    
    def sync_on_update(
        self,
        source_table: str,
        record_id: int,
        updated_fields: Dict[str, Any],
        old_values: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ë ˆì½”ë“œ ì—…ë°ì´íŠ¸ ì‹œ ì—°ê´€ ë°ì´í„° ë™ê¸°í™”
        
        Args:
            source_table: ì—…ë°ì´íŠ¸ëœ í…Œì´ë¸”
            record_id: ì—…ë°ì´íŠ¸ëœ ë ˆì½”ë“œ ID
            updated_fields: ì—…ë°ì´íŠ¸ëœ í•„ë“œë“¤
            old_values: ì´ì „ ê°’ë“¤ (ì„ íƒ)
        
        Returns:
            ë™ê¸°í™” ê²°ê³¼
        """
        result = {
            "source": f"{source_table}#{record_id}",
            "synced_tables": [],
            "errors": [],
            "timestamp": datetime.now().isoformat(),
        }
        
        # ìˆœí™˜ ë™ê¸°í™” ë°©ì§€
        sync_key = f"{source_table}:{record_id}"
        if sync_key in self._pending_syncs:
            logger.warning(f"ìˆœí™˜ ë™ê¸°í™” ê°ì§€: {sync_key}")
            return result
        
        self._pending_syncs.add(sync_key)
        
        try:
            dependencies = self.DEPENDENCY_GRAPH.get(source_table, [])
            
            for target_table, fk_field, action in dependencies:
                try:
                    sync_result = self._sync_dependent_table(
                        source_table=source_table,
                        source_id=record_id,
                        target_table=target_table,
                        fk_field=fk_field,
                        action=action,
                        updated_fields=updated_fields,
                        old_values=old_values
                    )
                    
                    if sync_result:
                        result["synced_tables"].append({
                            "table": target_table,
                            "action": action.value,
                            "affected_count": sync_result.get("count", 0)
                        })
                
                except Exception as e:
                    result["errors"].append({
                        "table": target_table,
                        "error": str(e)
                    })
                    logger.error(f"ë™ê¸°í™” ì‹¤íŒ¨: {target_table} - {e}")
            
            # ìºì‹œ ë¬´íš¨í™”
            self._invalidate_caches(source_table, record_id)
            
            # ë™ê¸°í™” ë¡œê·¸ ê¸°ë¡
            self._log_sync(result)
        
        finally:
            self._pending_syncs.discard(sync_key)
        
        return result
    
    def _sync_dependent_table(
        self,
        source_table: str,
        source_id: int,
        target_table: str,
        fk_field: str,
        action: SyncAction,
        updated_fields: Dict[str, Any],
        old_values: Optional[Dict[str, Any]]
    ) -> Optional[Dict[str, Any]]:
        """ì˜ì¡´ í…Œì´ë¸” ë™ê¸°í™” ì‹¤í–‰"""
        if not self.db:
            return None
        
        if action == SyncAction.UPDATE:
            # ë¹„ì •ê·œí™” í•„ë“œ ì—…ë°ì´íŠ¸
            return self._update_denormalized_fields(
                source_table, source_id, target_table, fk_field, updated_fields
            )
        
        elif action == SyncAction.DELETE:
            # CASCADE DELETE (ì£¼ì˜ í•„ìš”)
            pass
        
        elif action == SyncAction.RECALCULATE:
            # ì§‘ê³„ í•„ë“œ ì¬ê³„ì‚°
            return self._recalculate_aggregates(target_table, fk_field, source_id)
        
        return None
    
    def _update_denormalized_fields(
        self,
        source_table: str,
        source_id: int,
        target_table: str,
        fk_field: str,
        updated_fields: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë¹„ì •ê·œí™” í•„ë“œ ì—…ë°ì´íŠ¸"""
        # í•„ë“œ ë§¤í•‘ ì •ì˜
        field_mappings = {
            ("players", "matches"): {
                "name": ["player1_name", "player2_name"],
                "team": ["player1_team", "player2_team"],
            },
            ("players", "members"): {
                "name": ["player_name"],
            },
            ("players", "rankings"): {
                "name": ["player_name"],
                "team": ["team_name"],
            },
        }
        
        mapping = field_mappings.get((source_table, target_table), {})
        
        affected_count = 0
        
        for source_field, target_fields in mapping.items():
            if source_field in updated_fields:
                new_value = updated_fields[source_field]
                
                for target_field in target_fields:
                    try:
                        # FK í•„ë“œì— ë”°ë¼ ì¡°ê±´ ê²°ì •
                        if "player1" in fk_field or "player1" in target_field:
                            result = self.db.table(target_table).update({
                                target_field: new_value,
                                "updated_at": datetime.now().isoformat()
                            }).eq("player1_id", source_id).execute()
                        elif "player2" in fk_field or "player2" in target_field:
                            result = self.db.table(target_table).update({
                                target_field: new_value,
                                "updated_at": datetime.now().isoformat()
                            }).eq("player2_id", source_id).execute()
                        else:
                            result = self.db.table(target_table).update({
                                target_field: new_value,
                                "updated_at": datetime.now().isoformat()
                            }).eq(fk_field, source_id).execute()
                        
                        if result.data:
                            affected_count += len(result.data)
                    
                    except Exception as e:
                        logger.error(f"í•„ë“œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {target_table}.{target_field} - {e}")
        
        return {"count": affected_count}
    
    def _recalculate_aggregates(
        self,
        table: str,
        group_field: str,
        group_id: int
    ) -> Dict[str, Any]:
        """ì§‘ê³„ í•„ë“œ ì¬ê³„ì‚°"""
        if not self.db:
            return {"count": 0}
        
        affected_count = 0
        
        # ì˜ˆ: ì¢…ëª©ì˜ ê²½ê¸° ìˆ˜ ì¬ê³„ì‚°
        if table == "events":
            try:
                # ê²½ê¸° ìˆ˜ ì¡°íšŒ
                result = self.db.table("matches").select(
                    "id", count="exact"
                ).eq("event_id", group_id).execute()
                
                match_count = result.count or 0
                
                # ì¢…ëª© ì •ë³´ ì—…ë°ì´íŠ¸
                self.db.table("events").update({
                    "match_count": match_count,
                    "updated_at": datetime.now().isoformat()
                }).eq("id", group_id).execute()
                
                affected_count = 1
            except Exception as e:
                logger.error(f"ì§‘ê³„ ì¬ê³„ì‚° ì‹¤íŒ¨: {table} - {e}")
        
        return {"count": affected_count}
    
    def _invalidate_caches(self, source_table: str, record_id: int) -> None:
        """ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”"""
        cache_keys = self.CACHE_INVALIDATION_MAP.get(source_table, [])
        
        for cache_key in cache_keys:
            try:
                # ìºì‹œ ë¬´íš¨í™” ë¡œì§ (Redis ë“± ì‚¬ìš© ì‹œ)
                logger.debug(f"ìºì‹œ ë¬´íš¨í™”: {cache_key} (source: {source_table}#{record_id})")
                # redis.delete(f"{cache_key}:{record_id}")
            except Exception as e:
                logger.warning(f"ìºì‹œ ë¬´íš¨í™” ì‹¤íŒ¨: {cache_key} - {e}")
    
    def _log_sync(self, result: Dict[str, Any]) -> None:
        """ë™ê¸°í™” ë¡œê·¸ ê¸°ë¡"""
        self._sync_log.append(result)
        
        # ë¡œê·¸ í¬ê¸° ì œí•œ
        if len(self._sync_log) > 1000:
            self._sync_log = self._sync_log[-500:]
        
        # DBì— ë¡œê·¸ ì €ì¥ (ì„ íƒì )
        if self.db:
            try:
                self.db.table("sync_logs").insert({
                    "source": result["source"],
                    "synced_tables": result["synced_tables"],
                    "errors": result["errors"],
                    "created_at": result["timestamp"]
                }).execute()
            except Exception as e:
                logger.warning(f"ë™ê¸°í™” ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    # ==================== ì„ ìˆ˜ ë™ê¸°í™” íŠ¹í™” ë©”ì„œë“œ ====================
    
    def sync_player_update(
        self,
        player_id: int,
        updated_fields: Dict[str, Any],
        old_values: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ì„ ìˆ˜ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹œ ì „ì²´ ë™ê¸°í™”
        
        CLAUDE.md ì œ1ì›ì¹™ êµ¬í˜„:
        - ì„ ìˆ˜ í”„ë¡œí•„ â†’ members í…Œì´ë¸” ë™ê¸°í™”
        - ì„ ìˆ˜ í”„ë¡œí•„ â†’ ëª¨ë“  ê²½ê¸° ê²°ê³¼ ë™ê¸°í™”
        - ì„ ìˆ˜ í”„ë¡œí•„ â†’ ìˆœìœ„ ì •ë³´ ë™ê¸°í™”
        """
        result = self.sync_on_update("players", player_id, updated_fields, old_values)
        
        logger.info(f"ğŸ”„ ì„ ìˆ˜ ë™ê¸°í™” ì™„ë£Œ: player#{player_id}, {len(result['synced_tables'])}ê°œ í…Œì´ë¸”")
        
        return result
    
    def merge_players(
        self,
        target_player_id: int,
        source_player_ids: List[int]
    ) -> Dict[str, Any]:
        """
        ë™ëª…ì´ì¸ ë³‘í•©
        
        source_player_idsì˜ ëª¨ë“  ê¸°ë¡ì„ target_player_idë¡œ ë³‘í•©
        """
        result = {
            "target_player_id": target_player_id,
            "merged_player_ids": source_player_ids,
            "merged_records": [],
            "errors": [],
        }
        
        if not self.db:
            result["errors"].append("DB ì—°ê²° ì—†ìŒ")
            return result
        
        for source_id in source_player_ids:
            try:
                # ê²½ê¸° ê¸°ë¡ ì´ì „
                tables_to_update = [
                    ("matches", "player1_id"),
                    ("matches", "player2_id"),
                    ("matches", "winner_id"),
                    ("rankings", "player_id"),
                    ("members", "player_id"),
                ]
                
                for table, field in tables_to_update:
                    update_result = self.db.table(table).update({
                        field: target_player_id,
                        "updated_at": datetime.now().isoformat()
                    }).eq(field, source_id).execute()
                    
                    if update_result.data:
                        result["merged_records"].append({
                            "table": table,
                            "field": field,
                            "count": len(update_result.data)
                        })
                
                # ì†ŒìŠ¤ ì„ ìˆ˜ ë¹„í™œì„±í™”
                self.db.table("players").update({
                    "is_active": False,
                    "merged_into": target_player_id,
                    "updated_at": datetime.now().isoformat()
                }).eq("id", source_id).execute()
                
                logger.info(f"âœ… ì„ ìˆ˜ ë³‘í•©: {source_id} â†’ {target_player_id}")
            
            except Exception as e:
                result["errors"].append({
                    "source_id": source_id,
                    "error": str(e)
                })
                logger.error(f"âŒ ì„ ìˆ˜ ë³‘í•© ì‹¤íŒ¨: {source_id} - {e}")
        
        return result
    
    def split_player(
        self,
        player_id: int,
        match_ids_to_split: List[int]
    ) -> Dict[str, Any]:
        """
        ë™ëª…ì´ì¸ ë¶„ë¦¬
        
        íŠ¹ì • ê²½ê¸°ë“¤ì„ ìƒˆë¡œìš´ ì„ ìˆ˜ë¡œ ë¶„ë¦¬
        """
        result = {
            "original_player_id": player_id,
            "new_player_id": None,
            "split_records": [],
            "errors": [],
        }
        
        if not self.db:
            result["errors"].append("DB ì—°ê²° ì—†ìŒ")
            return result
        
        try:
            # ì›ë³¸ ì„ ìˆ˜ ì •ë³´ ì¡°íšŒ
            player_result = self.db.table("players").select("*").eq(
                "id", player_id
            ).execute()
            
            if not player_result.data:
                result["errors"].append(f"ì„ ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {player_id}")
                return result
            
            original_player = player_result.data[0]
            
            # ìƒˆ ì„ ìˆ˜ ìƒì„± (ì´ë¦„ì— ì ‘ë¯¸ì‚¬ ì¶”ê°€)
            new_player_data = {
                "name": f"{original_player['name']} (2)",
                "team": original_player.get("team"),
                "birth_year": original_player.get("birth_year"),
                "nationality": original_player.get("nationality", "KOR"),
                "is_active": True,
                "split_from": player_id,
            }
            
            new_player_result = self.db.table("players").insert(new_player_data).execute()
            
            if new_player_result.data:
                new_player_id = new_player_result.data[0]["id"]
                result["new_player_id"] = new_player_id
                
                # ì§€ì •ëœ ê²½ê¸°ë“¤ì„ ìƒˆ ì„ ìˆ˜ë¡œ ì´ì „
                for match_id in match_ids_to_split:
                    match_result = self.db.table("matches").select(
                        "player1_id", "player2_id", "winner_id"
                    ).eq("id", match_id).execute()
                    
                    if match_result.data:
                        match = match_result.data[0]
                        updates = {}
                        
                        if match["player1_id"] == player_id:
                            updates["player1_id"] = new_player_id
                        if match["player2_id"] == player_id:
                            updates["player2_id"] = new_player_id
                        if match["winner_id"] == player_id:
                            updates["winner_id"] = new_player_id
                        
                        if updates:
                            updates["updated_at"] = datetime.now().isoformat()
                            self.db.table("matches").update(updates).eq(
                                "id", match_id
                            ).execute()
                            
                            result["split_records"].append({
                                "match_id": match_id,
                                "fields_updated": list(updates.keys())
                            })
                
                logger.info(f"âœ… ì„ ìˆ˜ ë¶„ë¦¬: {player_id} â†’ ì‹ ê·œ {new_player_id}")
        
        except Exception as e:
            result["errors"].append(str(e))
            logger.error(f"âŒ ì„ ìˆ˜ ë¶„ë¦¬ ì‹¤íŒ¨: {e}")
        
        return result
    
    def get_sync_log(self, limit: int = 100) -> List[Dict[str, Any]]:
        """ìµœê·¼ ë™ê¸°í™” ë¡œê·¸ ì¡°íšŒ"""
        return self._sync_log[-limit:]
