í˜„ì¬ ê²ªê³  ê³„ì‹  ë¬¸ì œ(ë°ì´í„° ëˆ„ë½, ì—‰ëš±í•œ ë§¤í•‘, ì—°ë™ ì‹¤íŒ¨)ëŠ” **'ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬(Data Quality)'**ì™€ **'íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜'**ì˜ ë¶€ì¬ì—ì„œ ì˜µë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ 4ë‹¨ê³„ ê²€ì¦ ë° ê°œì„  í”„ë¡œì„¸ìŠ¤ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

1. ë°ì´í„° ìˆ˜ì§‘ ë‹¨ê³„ (Scraping): "ì›ë³¸ ë³´ì¡´ê³¼ ì¦‰ì‹œ ê²€ì¦"
ìŠ¤í¬ë˜í•‘ ì§í›„ì— ë°ì´í„°ê°€ ì˜¤ì—¼ë˜ë©´ ë’¤ìª½ DB ë‹¨ê³„ì—ì„œëŠ” ë³µêµ¬ê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.

Raw Data(ì›ë³¸) ì €ì¥ì†Œ êµ¬ì¶• (Data Lake ê°œë…):

ìŠ¤í¬ë˜í•‘í•œ ë°ì´í„°ë¥¼ ë°”ë¡œ ê°€ê³µí•´ì„œ DBì— ë„£ì§€ ë§ˆì„¸ìš”.

HTML íŒŒì¼ ê·¸ëŒ€ë¡œ í˜¹ì€ JSON í˜•íƒœë¡œ ë‚ ì§œë³„ í´ë”ì— ë¨¼ì € ì €ì¥í•˜ì„¸ìš”.

ì´ìœ : íŒŒì‹± ë¡œì§ì´ ì˜ëª»ë˜ì—ˆì„ ë•Œ, ì‚¬ì´íŠ¸ì— ë‹¤ì‹œ ì ‘ì†í•  í•„ìš” ì—†ì´ ì €ì¥ëœ HTML íŒŒì¼ë¡œ íŒŒì‹± ë¡œì§ë§Œ ìˆ˜ì •í•´ì„œ ë‹¤ì‹œ ëŒë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Pydantic ë“±ì„ ì´ìš©í•œ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ (Validation):

Pythonì„ ì“°ì‹ ë‹¤ë©´ Pydantic ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë„ì…í•˜ì„¸ìš”. ìŠ¤í¬ë˜í¼ê°€ ê°€ì ¸ì˜¨ ë°ì´í„°ê°€ ì˜ˆìƒí•œ íƒ€ì…(ìˆ«ì, ë‚ ì§œ í˜•ì‹, í•„ìˆ˜ í•„ë“œ ì¡´ì¬ ì—¬ë¶€)ì¸ì§€ ì½”ë“œ ë ˆë²¨ì—ì„œ ê°•ì œë¡œ ê²€ì‚¬í•©ë‹ˆë‹¤.

ì˜ˆ: "ìˆœìœ„" í•­ëª©ì— ìˆ«ìê°€ ì•„ë‹Œ í…ìŠ¤íŠ¸ê°€ ë“¤ì–´ì˜¤ë©´ ê·¸ ì¦‰ì‹œ ì—ëŸ¬ ë¡œê·¸ë¥¼ ë‚¨ê¸°ê³  í•´ë‹¹ ê±´ë§Œ ë³„ë„ë¡œ ë¹¼ë‘¡ë‹ˆë‹¤.

2. DB ì„¤ê³„ ë° ì ì¬ ë‹¨ê³„: "ê´€ê³„ ì„¤ì •ê³¼ ì‹ë³„ì"
"ì—°ê´€ëœ ë°ì´í„° í˜ì´ì§€ë¼ë¦¬ ì—…ë°ì´íŠ¸ê°€ ì•ˆ ëœë‹¤"ëŠ” ê²ƒì€ **DB ì •ê·œí™”(Normalization)**ì™€ ì™¸ë˜ í‚¤(Foreign Key) ì„¤ì •ì´ ë¯¸í¡í•˜ë‹¤ëŠ” ì‹ í˜¸ì…ë‹ˆë‹¤.

ê³ ìœ  ì‹ë³„ì(Unique ID) ìƒì„± ì „ëµ:

íœì‹±í˜‘íšŒ ì‚¬ì´íŠ¸ì—ì„œ ì„ ìˆ˜ë¥¼ êµ¬ë³„í•  ë•Œ ë‹¨ìˆœíˆ 'ì´ë¦„'ìœ¼ë¡œ í•˜ë©´ ë™ëª…ì´ì¸ ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.

í˜‘íšŒ ì‚¬ì´íŠ¸ URLì— ìˆëŠ” player_id=1234 ê°™ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì•„ë‚´ì–´ ì´ë¥¼ DBì˜ Primary Key(PK)ë¡œ ì¨ì•¼ í•©ë‹ˆë‹¤. ì—†ë‹¤ë©´ ìƒë…„ì›”ì¼+ì´ë¦„ì„ ì¡°í•©í•˜ì—¬ ê³ ìœ  í‚¤ë¥¼ ë§Œë“œì„¸ìš”.

Upsert (Update + Insert) ë¡œì§ ì ìš©:

ë°ì´í„°ë¥¼ ë„£ì„ ë•Œ ë¬´ì¡°ê±´ INSERTë§Œ í•˜ë©´ ì¤‘ë³µì´ ìŒ“ì…ë‹ˆë‹¤.

"ì´ IDê°€ ì´ë¯¸ ìˆìœ¼ë©´ ì •ë³´ë¥¼ ê°±ì‹ (Update)í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±(Insert)í•œë‹¤"ëŠ” Upsert ë¡œì§ì„ íŒŒì´í”„ë¼ì¸ì— ì ìš©í•´ì•¼ ì—°ë™ì„±ì´ ë³´ì¥ë©ë‹ˆë‹¤.

ì°¸ì¡° ë¬´ê²°ì„± (Foreign Key) ê°•ì œ:

[ê²½ê¸° ê²°ê³¼ í…Œì´ë¸”]ì— ì„ ìˆ˜ ì´ë¦„ë§Œ í…ìŠ¤íŠ¸ë¡œ ë„£ì§€ ë§ê³ , [ì„ ìˆ˜ í…Œì´ë¸”]ì˜ IDë¥¼ ë„£ìœ¼ì„¸ìš”.

ì´ë ‡ê²Œ í•˜ë©´ [ì„ ìˆ˜ í…Œì´ë¸”]ì˜ ì •ë³´ë§Œ ì—…ë°ì´íŠ¸í•´ë„, ì—°ê²°ëœ ëª¨ë“  [ê²½ê¸° ê²°ê³¼]ì—ì„œ ì„ ìˆ˜ ì •ë³´ê°€ ìµœì‹ ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.

3. ê²€ì¦ ë° ëª¨ë‹ˆí„°ë§ (QA): "ìë™í™”ëœ ë¹„êµ"
ì—‰ëš±í•œ ë°ì´í„°ê°€ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

Count Check (ê°œìˆ˜ ë¹„êµ):

ìŠ¤í¬ë˜í¼ê°€ "ì˜¤ëŠ˜ ìˆ˜ì§‘í•œ ë¦¬ìŠ¤íŠ¸ ê°œìˆ˜: 50ê°œ"ë¼ê³  ë¡œê·¸ë¥¼ ë‚¨ê¸°ê²Œ í•˜ê³ , DBì— ì ì¬ëœ í›„ "ì˜¤ëŠ˜ ì ì¬ëœ ë°ì´í„°: 50ê°œ"ì¸ì§€ ìë™ìœ¼ë¡œ ë¹„êµí•˜ì—¬ ë‹¤ë¥´ë©´ ì•Œë¦¼ì„ ë³´ëƒ…ë‹ˆë‹¤.

ìƒ˜í”Œë§ ê²€ìˆ˜ (Human-in-the-loop):

ë§¤ë²ˆ ì „ì²´ë¥¼ ë³¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëœë¤ìœ¼ë¡œ 5ê°œì˜ ë°ì´í„°ë¥¼ ë½‘ì•„ ì›ë³¸ ì‚¬ì´íŠ¸ ë§í¬ì™€ ë‚˜ë€íˆ ë³´ì—¬ì£¼ëŠ” ê°„ë‹¨í•œ 'ê²€ìˆ˜ í˜ì´ì§€'ë¥¼ ë§Œë“œì„¸ìš”. ëˆˆìœ¼ë¡œ í™•ì¸í•˜ëŠ” ê²ƒì´ ê°€ì¥ ë¹ ë¥¼ ë•Œê°€ ë§ìŠµë‹ˆë‹¤.

4. íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜ ê°œì„ 
ë‹¨ìˆœ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ì´ ì•„ë‹ˆë¼, ì›Œí¬í”Œë¡œìš°ë¥¼ ë§Œë“œì„¸ìš”.

Extract: HTML ë‹¤ìš´ë¡œë“œ ë° ì €ì¥ (ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§ í•„ìˆ˜).

Transform: HTML íŒŒì‹± -> Pydantic ê²€ì¦ -> ì •ì œëœ ë°ì´í„°(ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸) ìƒì„±.

Load: DB ì—°ê²° -> íŠ¸ëœì­ì…˜ ì‹œì‘ -> Upsert ìˆ˜í–‰ -> Commit.

ì¶”ì²œí•˜ëŠ” ë‹¤ìŒ ë‹¨ê³„
í˜„ì¬ ê°€ì¥ ë¬¸ì œê°€ ë˜ëŠ” ë¶€ë¶„ì˜ **"DB í…Œì´ë¸” ì„¤ê³„ë„(ERD í˜¹ì€ ìŠ¤í‚¤ë§ˆ)"**ë‚˜ **"ìŠ¤í¬ë˜í•‘ ëœ ë°ì´í„°ì˜ ì˜ˆì‹œ(JSON)"**ë¥¼ ë³´ì—¬ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?

ê·¸ëŸ¬ë©´ ì œê°€ "ì–´ëŠ ë¶€ë¶„ì—ì„œ ë°ì´í„° ê´€ê³„ê°€ ëŠì–´ì¡ŒëŠ”ì§€", í˜¹ì€ "ì–´ë–¤ ê²€ì¦ ì½”ë“œë¥¼ ë„£ì–´ì•¼ ì—‰ëš±í•œ ë°ì´í„°ë¥¼ ë§‰ì„ ìˆ˜ ìˆëŠ”ì§€" êµ¬ì²´ì ì¸ íŒŒì´ì¬ ì½”ë“œë‚˜ SQL ì¿¼ë¦¬ë¡œ ì§„ë‹¨í•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
//

ğŸ”§ ìŠ¤í¬ë˜í•‘ ë°ì´í„° ê²€ì¦ ë° íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ êµ¬ì¶•
ë‹¹ì‹ ì˜ í˜„ì¬ ë¬¸ì œì  ë¶„ì„
text
âŒ í˜„ì¬ ìƒí™©:
1. ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ (ë°ì´í„° ëˆ„ë½)
2. ë°ì´í„° ì˜¤ë¥˜ (ì—‰ëš±í•œ ë°ì´í„°)
3. DB êµ¬ì„± ì˜¤ë¥˜ (í•„ë“œ ë§¤ì¹­ ì‹¤íŒ¨)
4. ë°ì´í„° ê°„ ì—°ë™ ì‹¤íŒ¨ (í˜ì´ì§€ ê°„ ì‹±í¬ ì•ˆ ë¨)
5. ìˆ˜ë™ìœ¼ë¡œë§Œ ìˆ˜ì • ê°€ëŠ¥ (ìë™í™” ë¶ˆê°€)

â†’ ê·¼ë³¸ ì›ì¸: "ê²€ì¦ ë‹¨ê³„ ì—†ìŒ" + "íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°ë§ ì—†ìŒ"
ğŸ“Š 4ë‹¨ê³„ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜
â€‹
Stage 1: ì›ë³¸ ì €ì¥ (Raw Storage)
python
# ìŠ¤í¬ë˜í•‘ ì§í›„, ê²€ì¦ ì—†ì´ ë°”ë¡œ ì €ì¥
# ëª©ì : ì›ë³¸ ë³´ì¡´, ì´í›„ ë””ë²„ê¹… ê°€ëŠ¥

class RawDataStorage:
    def save_raw_scrape(self, source_url, html_content, timestamp):
        """
        í˜‘íšŒ ì›ë³¸ HTMLì„ ê·¸ëŒ€ë¡œ ì €ì¥
        """
        raw_data = {
            'source': source_url,
            'content': html_content,
            'timestamp': timestamp,
            'scrape_id': uuid.uuid4()
        }
        # MongoDB ë˜ëŠ” S3ì— ì €ì¥ (ê²€ì¦ ì—†ì´)
        return raw_data['scrape_id']
ì™œ ì´ ë‹¨ê³„ê°€ í•„ìš”í•œê°€?

ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ì‹œ ì›ë³¸ í™•ì¸ ê°€ëŠ¥

íŒŒì„œ ë¡œì§ ë³€ê²½ í›„ ì¬ì²˜ë¦¬ ê°€ëŠ¥

ë””ë²„ê¹… ì‹œ "ì–´ë””ì„œ ì˜ëª» ì¶”ì¶œí–ˆë‚˜" íŒŒì•… ìš©ì´

Stage 2: ì¶”ì¶œ ë° íŒŒì‹± (Extract & Parse) - ê¸°ìˆ  ê²€ì¦
python
# ë°ì´í„° í˜•ì‹, í•„ë“œ, ë°ì´í„° íƒ€ì… ê²€ì¦

from pydantic import BaseModel, validator
from typing import Optional

class PlayerMatchSchema(BaseModel):
    """ê²½ê¸° ê²°ê³¼ ë°ì´í„° ìŠ¤í‚¤ë§ˆ"""
    player_id: str
    player_name: str
    club_name: str
    match_date: datetime
    match_type: str  # "5_point" or "15_point"
    result: str  # "W" or "L"
    opponent_name: str
    
    @validator('player_id')
    def validate_player_id(cls, v):
        if not v or len(v) < 3:
            raise ValueError('Invalid player_id')
        return v
    
    @validator('result')
    def validate_result(cls, v):
        if v not in ['W', 'L']:
            raise ValueError('Result must be W or L')
        return v

class TechnicalValidation:
    def validate_scraped_data(self, raw_html, scrape_id):
        """
        Stage 1ì—ì„œ ì €ì¥í•œ ì›ë³¸ì„ íŒŒì‹±í•˜ê³  ìŠ¤í‚¤ë§ˆ ê²€ì¦
        """
        try:
            # HTML íŒŒì‹±
            parsed_data = self.parse_html(raw_html)
            
            # ìŠ¤í‚¤ë§ˆ ê²€ì¦ (ìë™)
            validated_records = []
            errors = []
            
            for record in parsed_data:
                try:
                    validated_record = PlayerMatchSchema(**record)
                    validated_records.append(validated_record)
                except ValidationError as e:
                    errors.append({
                        'record': record,
                        'error': str(e),
                        'severity': 'CRITICAL'
                    })
            
            return {
                'scrape_id': scrape_id,
                'valid_records': validated_records,
                'errors': errors,
                'pass_rate': len(validated_records) / (len(validated_records) + len(errors))
            }
        except Exception as e:
            return {
                'scrape_id': scrape_id,
                'valid_records': [],
                'errors': [{'error': str(e), 'severity': 'CRITICAL'}],
                'pass_rate': 0
            }
ê²€ì¦ ë‚´ìš©:

âœ… í•„ë“œ ì¡´ì¬ ì—¬ë¶€

âœ… ë°ì´í„° íƒ€ì… (ë¬¸ìì—´, ë‚ ì§œ, ìˆ«ì)

âœ… í•„ìˆ˜ í•„ë“œ ì±„ìš°ê¸°

âœ… ê¸°ë³¸ ë²”ìœ„ ê²€ì¦ (ë‚ ì§œëŠ” ê³¼ê±°, ìˆ˜ì¹˜ëŠ” ì–‘ìˆ˜)

Stage 3: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê²€ì¦ (Context Validation)
python
class BusinessLogicValidation:
    """
    íœì‹± ë„ë©”ì¸ íŠ¹í™” ê²€ì¦
    """
    
    def validate_match_consistency(self, record):
        """
        ê²½ê¸° ê²°ê³¼ì˜ ë…¼ë¦¬ì  ì¼ê´€ì„± í™•ì¸
        """
        errors = []
        
        # ì²´í¬ 1: ê°™ì€ ë‚  ê°™ì€ ì„ ìˆ˜ ì¤‘ë³µ ê²½ê¸°?
        if self.has_duplicate_matches(record['player_id'], record['match_date']):
            errors.append({
                'type': 'DUPLICATE_MATCH',
                'severity': 'MEDIUM',
                'message': f"ì„ ìˆ˜ {record['player_name']}ì´ ê°™ì€ ë‚ ì— ê°™ì€ ìƒëŒ€ì™€ ì—¬ëŸ¬ ê²½ê¸°í–ˆìŒ"
            })
        
        # ì²´í¬ 2: ëŒ€íšŒ ì •ë³´ëŠ” í˜‘íšŒ ê³µì‹ ëŒ€íšŒì¸ê°€?
        if not self.is_official_tournament(record['tournament_id']):
            errors.append({
                'type': 'UNOFFICIAL_TOURNAMENT',
                'severity': 'LOW',
                'message': f"ëŒ€íšŒ {record['tournament_id']}ê°€ í˜‘íšŒ ê³µì‹ ë“±ë¡ ëŒ€íšŒ ì•„ë‹˜"
            })
        
        # ì²´í¬ 3: ì„ ìˆ˜ì˜ ë‚˜ì´ì™€ ê²½ê¸° ê¸‰ìˆ˜ ì¼ì¹˜?
        if not self.matches_age_category(record['player_id'], record['category']):
            errors.append({
                'type': 'AGE_MISMATCH',
                'severity': 'HIGH',
                'message': f"ì„ ìˆ˜ ë‚˜ì´ì™€ ê²½ê¸° ê¸‰ìˆ˜ ë¶ˆì¼ì¹˜"
            })
        
        # ì²´í¬ 4: ìƒëŒ€ ì„ ìˆ˜ ì •ë³´ëŠ” DBì— ìˆëŠ”ê°€?
        opponent_in_db = self.find_player_by_name(record['opponent_name'])
        if not opponent_in_db:
            # ê²½ê³ ì§€ë§Œ í†µê³¼ (ìƒˆ ì„ ìˆ˜ì¼ ìˆ˜ ìˆìŒ)
            errors.append({
                'type': 'OPPONENT_NOT_FOUND',
                'severity': 'LOW',
                'message': f"ìƒëŒ€ ì„ ìˆ˜ {record['opponent_name']}ê°€ DBì— ì—†ìŒ"
            })
        
        return errors
    
    def validate_player_progression(self, player_id):
        """
        ì„ ìˆ˜ì˜ ì„±ê³¼ê°€ ë§ì´ ë˜ëŠ”ê°€?
        """
        errors = []
        recent_records = self.get_player_recent_matches(player_id, days=30)
        
        # ê¸‰ì‘ìŠ¤ëŸ¬ìš´ ì„±ê³¼ ê¸‰ë³€?
        if self.is_anomalous_progression(recent_records):
            errors.append({
                'type': 'ANOMALOUS_PROGRESSION',
                'severity': 'MEDIUM',
                'message': f"ì„ ìˆ˜ì˜ ì„±ê³¼ê°€ ê¸‰ê²©í•˜ê²Œ ë³€í•¨ (ë°ì´í„° ì˜¤ë¥˜ ì˜ì‹¬)"
            })
        
        return errors
    
    def validate_referential_integrity(self, record):
        """
        FK ê´€ê³„ ê²€ì¦
        ì„ ìˆ˜ â† ê²½ê¸° â†’ ëŒ€íšŒ
        """
        errors = []
        
        # ì„ ìˆ˜ ì •ë³´ í™•ì¸
        player = self.db.players.find_one({'player_id': record['player_id']})
        if not player:
            errors.append({
                'type': 'PLAYER_NOT_FOUND',
                'severity': 'CRITICAL',
                'message': f"ì„ ìˆ˜ ì •ë³´ ì—†ìŒ: {record['player_id']}"
            })
        
        # ëŒ€íšŒ ì •ë³´ í™•ì¸
        tournament = self.db.tournaments.find_one({'tournament_id': record['tournament_id']})
        if not tournament:
            errors.append({
                'type': 'TOURNAMENT_NOT_FOUND',
                'severity': 'CRITICAL',
                'message': f"ëŒ€íšŒ ì •ë³´ ì—†ìŒ: {record['tournament_id']}"
            })
        
        # ë‚ ì§œ ì¼ê´€ì„± (ê²½ê¸° ë‚ ì§œ < ì˜¤ëŠ˜)
        if record['match_date'] > datetime.now():
            errors.append({
                'type': 'FUTURE_DATE',
                'severity': 'CRITICAL',
                'message': f"ê²½ê¸° ë‚ ì§œê°€ ë¯¸ë˜: {record['match_date']}"
            })
        
        return errors
ê²€ì¦ ë‚´ìš©:

âœ… ì¤‘ë³µ ê²½ê¸° ê°ì§€

âœ… ê³µì‹ ëŒ€íšŒ í™•ì¸

âœ… ì„ ìˆ˜ ë‚˜ì´ì™€ ê¸‰ìˆ˜ ì¼ì¹˜

âœ… ìƒëŒ€ ì„ ìˆ˜ ì¡´ì¬ ì—¬ë¶€

âœ… ì„ ìˆ˜ ì„±ê³¼ ì´ìƒì¹˜ íƒì§€

âœ… ì™¸ë˜í‚¤(FK) ë¬´ê²°ì„±

Stage 4: ìµœì¢… ì €ì¥ (Validated Storage)
python
class ValidatedDataStorage:
    def store_validated_data(self, validation_result):
        """
        ê²€ì¦ í†µê³¼í•œ ë°ì´í„°ë§Œ í”„ë¡œë•ì…˜ DBì— ì €ì¥
        """
        if validation_result['technical_errors']:
            # Stage 2 ê²€ì¦ ì‹¤íŒ¨ â†’ ì €ì¥ ì•ˆ í•¨
            return {
                'status': 'REJECTED',
                'reason': 'Technical validation failed',
                'errors': validation_result['technical_errors']
            }
        
        if validation_result['business_errors']:
            critical_errors = [e for e in validation_result['business_errors'] 
                             if e['severity'] == 'CRITICAL']
            
            if critical_errors:
                # CRITICAL ì—ëŸ¬ ìˆìœ¼ë©´ ì €ì¥ ì•ˆ í•¨
                return {
                    'status': 'REJECTED',
                    'reason': 'Business logic validation failed',
                    'errors': critical_errors
                }
            else:
                # WARNING/INFOë§Œ ìˆìœ¼ë©´ ì €ì¥ (ëŒ€ì‹  flag í‘œì‹œ)
                for record in validation_result['records']:
                    record['has_warnings'] = True
                    record['warnings'] = validation_result['business_errors']
        
        # í”„ë¡œë•ì…˜ DBì— ì €ì¥
        for record in validation_result['records']:
            record['validated_at'] = datetime.now()
            record['validation_version'] = '1.0'
            self.db.matches.insert_one(record)
        
        # ë³€ê²½ì‚¬í•­ ì´ë²¤íŠ¸ ë°œí–‰ (ë‹¤ë¥¸ í˜ì´ì§€ ì‹±í¬ìš©)
        for record in validation_result['records']:
            self.publish_event({
                'type': 'MATCH_CREATED',
                'player_id': record['player_id'],
                'tournament_id': record['tournament_id'],
                'record': record
            })
        
        return {
            'status': 'ACCEPTED',
            'records_saved': len(validation_result['records'])
        }
ğŸ”„ ë°ì´í„° ê°„ ì—°ë™ ë¬¸ì œ í•´ê²°
ë¬¸ì œ: "í•œìª½ì´ ì—…ë°ì´íŠ¸ë˜ë©´ ëª¨ë‘ ì—…ë°ì´íŠ¸"
python
# âŒ í˜„ì¬ ë°©ì‹ (ë™ê¸°ì‹, ì‹¤íŒ¨ ê°€ëŠ¥)
def update_match(match_id, new_result):
    match = db.matches.update_one({'match_id': match_id}, {'result': new_result})
    
    # ì´í›„ ìˆ˜ë™ìœ¼ë¡œ ê´€ë ¨ ë°ì´í„° ì—…ë°ì´íŠ¸?
    # â†’ ë¹ ëœ¨ë¦¼ ê°€ëŠ¥, ì¼ê´€ì„± ì—†ìŒ
âœ… í•´ê²°ì±…: Event-Driven ì•„í‚¤í…ì²˜
python
from kafka import KafkaProducer, KafkaConsumer
import json

class EventPublisher:
    def __init__(self):
        self.producer = KafkaProducer(
            bootstrap_servers=['localhost:9092'],
            value_serializer=lambda v: json.dumps(v).encode('utf-8')
        )
    
    def publish_match_update(self, match_id, changes):
        """
        ê²½ê¸° ì •ë³´ê°€ ë³€ê²½ë˜ë©´ ì´ë²¤íŠ¸ ë°œí–‰
        """
        event = {
            'event_type': 'MATCH_UPDATED',
            'match_id': match_id,
            'changes': changes,
            'timestamp': datetime.now().isoformat(),
            'source': 'data_pipeline'
        }
        
        # Kafka í† í”½ìœ¼ë¡œ ë°œí–‰
        self.producer.send('match_updates', value=event)
        print(f"âœ… Event published: {event}")

class EventSubscriber:
    def __init__(self):
        self.consumer = KafkaConsumer(
            'match_updates',
            bootstrap_servers=['localhost:9092'],
            value_deserializer=lambda m: json.loads(m.decode('utf-8'))
        )
    
    def start_listening(self):
        """
        ê²½ê¸° ë³€ê²½ ì´ë²¤íŠ¸ ê°ì§€ â†’ ê´€ë ¨ í˜ì´ì§€ ìë™ ì—…ë°ì´íŠ¸
        """
        for event in self.consumer:
            if event['event_type'] == 'MATCH_UPDATED':
                self.handle_match_update(event)
    
    def handle_match_update(self, event):
        """
        1ê°œ ê²½ê¸° ë³€ê²½ â†’ 10ê°œ í˜ì´ì§€ ìë™ ì—…ë°ì´íŠ¸
        """
        match_id = event['match_id']
        match = db.matches.find_one({'match_id': match_id})
        
        # ê´€ë ¨ ë°ì´í„° ìë™ ì—…ë°ì´íŠ¸
        updates = {
            'player_profile': self.update_player_stats(match),
            'opponent_profile': self.update_opponent_stats(match),
            'tournament_page': self.update_tournament_results(match),
            'rankings_page': self.update_rankings(match),
            'club_page': self.update_club_stats(match),
        }
        
        # ëª¨ë“  í˜ì´ì§€ ì¼ê´„ ì—…ë°ì´íŠ¸
        for page_type, update_data in updates.items():
            db[page_type].update_one(
                {'_id': update_data['_id']},
                {'$set': update_data}
            )
            print(f"âœ… {page_type} updated")

# ì‚¬ìš© ì˜ˆì‹œ
publisher = EventPublisher()
subscriber = EventSubscriber()

# ê²½ê¸° ê²°ê³¼ ë³€ê²½
publisher.publish_match_update('match_123', {'result': 'W'})

# ìë™ìœ¼ë¡œ 10ê°œ í˜ì´ì§€ ì—…ë°ì´íŠ¸ë¨
subscriber.start_listening()
ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
ì‹¤ì‹œê°„ ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
python
from datetime import datetime, timedelta

class DataQualityMonitoring:
    def generate_report(self):
        """
        ë§¤ì¼ ìë™ìœ¼ë¡œ ìƒì„±ë˜ëŠ” ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸
        """
        report = {
            'date': datetime.now(),
            'pipeline_health': {
                'stage_2_pass_rate': self.calculate_stage2_pass_rate(),  # ëª©í‘œ: 90-95%
                'stage_3_pass_rate': self.calculate_stage3_pass_rate(),  # ëª©í‘œ: 70-80%
                'final_pass_rate': self.calculate_final_pass_rate(),     # ëª©í‘œ: 95%+
                'false_positive_rate': self.calculate_false_positive(),  # ëª©í‘œ: <5%
            },
            'error_summary': {
                'total_errors': self.count_total_errors(),
                'critical_errors': self.count_critical_errors(),
                'warnings': self.count_warnings(),
                'top_error_types': self.get_top_error_types(top_n=5)
            },
            'data_freshness': {
                'last_scrape': self.get_last_scrape_time(),
                'last_validation': self.get_last_validation_time(),
                'records_updated': self.count_updated_records_today(),
                'freshness_score': self.calculate_freshness_score()  # 0-100
            }
        }
        
        # ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ì•Œë¦¼
        if report['pipeline_health']['stage_2_pass_rate'] < 0.85:
            self.send_alert('âš ï¸ Stage 2 pass rate low', report)
        
        if report['error_summary']['critical_errors'] > 10:
            self.send_alert('ğŸš¨ Critical errors detected', report)
        
        return report
    
    def get_top_error_types(self, top_n=5):
        """
        ê°€ì¥ ë¹ˆë²ˆí•œ ì—ëŸ¬ íƒ€ì… í‘œì‹œ
        ì˜ˆ: "PLAYER_NOT_FOUND 45ê±´", "DUPLICATE_MATCH 23ê±´"
        """
        pipeline_log = db.pipeline_logs.find(
            {'created_at': {'$gte': datetime.now() - timedelta(days=1)}}
        )
        
        error_counts = {}
        for log in pipeline_log:
            error_type = log.get('error_type', 'UNKNOWN')
            error_counts[error_type] = error_counts.get(error_type, 0) + 1
        
        return sorted(error_counts.items(), key=lambda x: x[1], reverse=True)[:top_n]
    
    def create_dashboard_json(self):
        """
        ì›¹ ëŒ€ì‹œë³´ë“œìš© JSON
        """
        report = self.generate_report()
        
        return {
            'status': 'HEALTHY' if report['pipeline_health']['final_pass_rate'] > 0.95 else 'WARNING',
            'metrics': {
                'pass_rate': f"{report['pipeline_health']['final_pass_rate']*100:.1f}%",
                'error_count': report['error_summary']['total_errors'],
                'freshness': f"{report['data_freshness']['freshness_score']}/100",
            },
            'charts': {
                'stage2_vs_stage3': self.plot_validation_stages(),
                'error_trend': self.plot_error_trend(days=30),
                'top_errors': report['error_summary']['top_error_types']
            }
        }
ğŸ› ï¸ êµ¬í˜„ ìˆœì„œ (ìš°ì„ ìˆœìœ„)
Phase 1: ê¸°ì´ˆ (1-2ì£¼)
text
âœ… 1. Raw Storage êµ¬ì¶•
   - MongoDBì— ì›ë³¸ HTML ì €ì¥
   - ìŠ¤í¬ë˜í•‘ ë¡œê·¸ ê¸°ë¡

âœ… 2. Technical Validation (Stage 2)
   - Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜
   - í•„ë“œ ê²€ì¦ ìë™í™”

âœ… 3. ì—ëŸ¬ ë¡œê¹…
   - ê²€ì¦ ì‹¤íŒ¨ í•­ëª© DBì— ì €ì¥
   - ìƒì„¸í•œ ì—ëŸ¬ ë©”ì‹œì§€ ê¸°ë¡
Phase 2: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ (2-3ì£¼)
text
âœ… 4. Business Logic Validation (Stage 3)
   - ì¤‘ë³µ ê²½ê¸° ê°ì§€
   - FK ë¬´ê²°ì„± ê²€ì¦
   - ì´ìƒì¹˜ íƒì§€

âœ… 5. Validated Storage (Stage 4)
   - ê²€ì¦ í†µê³¼ ë°ì´í„°ë§Œ ì €ì¥
   - ë©”íƒ€ë°ì´í„° ì¶”ê°€ (validation_timestamp, warnings ë“±)
Phase 3: ìë™í™” (2-3ì£¼)
text
âœ… 6. Event-Driven ë™ê¸°í™”
   - Kafka ë˜ëŠ” Redis Pub/Sub êµ¬ì„±
   - ê²½ê¸° ë³€ê²½ ì‹œ 10ê°œ í˜ì´ì§€ ìë™ ì—…ë°ì´íŠ¸

âœ… 7. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
   - ì‹¤ì‹œê°„ í’ˆì§ˆ ì§€í‘œ
   - ìë™ ì•Œë¦¼ ì‹œìŠ¤í…œ
ğŸ’» ìµœì†Œ êµ¬í˜„ ì½”ë“œ (ë°”ë¡œ ì¨ë„ ë¨)
python
# requirements.txt
pydantic==2.0
pymongo==4.5
kafka-python==2.0
apscheduler==3.10

# main.py
from pydantic import BaseModel, validator
from pymongo import MongoClient
from typing import List
from datetime import datetime
import json

# DB ì—°ê²°
client = MongoClient('mongodb://localhost:27017')
db = client['fencing_tracker']

# 1. ìŠ¤í‚¤ë§ˆ ì •ì˜
class Match(BaseModel):
    player_id: str
    player_name: str
    match_date: datetime
    result: str  # 'W' or 'L'
    
    @validator('result')
    def validate_result(cls, v):
        if v not in ['W', 'L']:
            raise ValueError('Invalid result')
        return v

# 2. ê²€ì¦ í•¨ìˆ˜
def validate_match_data(raw_data):
    try:
        match = Match(**raw_data)
        return {'valid': True, 'data': match}
    except Exception as e:
        return {'valid': False, 'error': str(e)}

# 3. ì €ì¥ í•¨ìˆ˜
def save_validated_match(match_data):
    if not validate_match_data(match_data)['valid']:
        return {'status': 'REJECTED', 'reason': 'Validation failed'}
    
    db.matches.insert_one(match_data)
    
    # 4. ì´ë²¤íŠ¸ ë°œí–‰
    db.events.insert_one({
        'event_type': 'MATCH_CREATED',
        'match_data': match_data,
        'timestamp': datetime.now()
    })
    
    return {'status': 'ACCEPTED'}

# 5. ì¼ì¼ ë¦¬í¬íŠ¸
def generate_daily_report():
    total = db.matches.count_documents({'created_at': {'$gte': datetime.now().replace(hour=0, minute=0)}})
    errors = db.validation_errors.count_documents({'created_at': {'$gte': datetime.now().replace(hour=0, minute=0)}})
    
    print(f"""
    ğŸ“Š Data Pipeline Report - {datetime.now().date()}
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    âœ… Valid Records: {total}
    âŒ Validation Errors: {errors}
    ğŸ“ˆ Pass Rate: {(total/(total+errors)*100 if total+errors > 0 else 0):.1f}%
    """)

# ì‚¬ìš© ì˜ˆì‹œ
test_data = {
    'player_id': 'P001',
    'player_name': 'ê¹€ì² ìˆ˜',
    'match_date': datetime.now(),
    'result': 'W'
}

result = save_validated_match(test_data)
print(result)

generate_daily_report()
ğŸ¯ ê¸°ëŒ€ íš¨ê³¼
ë¬¸ì œ	í•´ê²°ì±…	ê¸°ëŒ€íš¨ê³¼
ë°ì´í„° ì˜¤ë¥˜	Stage 2-3 ê²€ì¦	ì˜¤ë¥˜ ê°ì§€ìœ¨ 99%
ëˆ„ë½ëœ ë°ì´í„°	ì›ë³¸ ì €ì¥ + ì¬ì²˜ë¦¬	ë°ì´í„° ë³µêµ¬ ê°€ëŠ¥
í˜ì´ì§€ ë¶ˆì¼ì¹˜	Event-Driven ë™ê¸°í™”	ìë™ ì¼ê´„ ì—…ë°ì´íŠ¸
ë””ë²„ê¹… ì–´ë ¤ì›€	ìƒì„¸ ì—ëŸ¬ ë¡œê¹…	ë¬¸ì œ ì›ì¸ 5ë¶„ ë‚´ íŒŒì•…
ìˆ˜ë™ ìˆ˜ì •	ìë™í™” íŒŒì´í”„ë¼ì¸	99% ìë™í™”
ì´ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë©´, **"í•œ ë²ˆ ì„¤ì •í•˜ë©´ ìë™ìœ¼ë¡œ ê²€ì¦í•˜ê³  ì €ì¥í•˜ê³  ë™ê¸°í™”"**ë˜ëŠ” ì™„ì „ ìë™í™” ë°ì´í„° íŒŒì´í”„ë¼ì¸ì´ ì™„ì„±ë©ë‹ˆë‹¤! ğŸ‘