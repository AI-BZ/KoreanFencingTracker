"""
íŒŒì´í”„ë¼ì¸ í†µí•© ìŠ¤í¬ë˜í¼

KFFFullScraper + DataPipeline + Supabase í†µí•©
- ìŠ¤í¬ë˜í•‘ â†’ ê²€ì¦ â†’ ì €ì¥ íŒŒì´í”„ë¼ì¸
- ì‹¤ì‹œê°„ ê²€ì¦ ë° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
"""
import asyncio
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import asdict
from loguru import logger

# ìŠ¤í¬ë˜í¼
from scraper.full_scraper import KFFFullScraper, Competition

# ë°ì´í„° íŒŒì´í”„ë¼ì¸
from data_pipeline import (
    DataPipeline,
    DataQualityMonitor,
    DataSynchronizer,
    ValidationResult,
)

# Supabase
from database.supabase_client import get_supabase_client


class PipelineScraper:
    """
    íŒŒì´í”„ë¼ì¸ í†µí•© ìŠ¤í¬ë˜í¼

    ìŠ¤í¬ë˜í•‘ â†’ ê²€ì¦ â†’ ì €ì¥ â†’ ë™ê¸°í™”
    """

    def __init__(self, headless: bool = True):
        self.headless = headless
        self.scraper: Optional[KFFFullScraper] = None
        self.pipeline: Optional[DataPipeline] = None
        self.monitor: Optional[DataQualityMonitor] = None
        self.syncer: Optional[DataSynchronizer] = None
        self.db = None

        # í†µê³„
        self.stats = {
            "competitions_scraped": 0,
            "events_scraped": 0,
            "events_validated": 0,
            "events_saved": 0,
            "validation_errors": 0,
            "validation_warnings": 0,
        }

    async def __aenter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        # Supabase í´ë¼ì´ì–¸íŠ¸
        self.db = get_supabase_client()

        # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        self.pipeline = DataPipeline(db_client=self.db)
        self.monitor = DataQualityMonitor(db_client=self.db)
        self.syncer = DataSynchronizer(db_client=self.db)

        # ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
        self.scraper = KFFFullScraper(headless=self.headless)
        await self.scraper.__aenter__()

        logger.info("âœ… PipelineScraper ì´ˆê¸°í™” ì™„ë£Œ")
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        if self.scraper:
            await self.scraper.__aexit__(exc_type, exc_val, exc_tb)

        # ìµœì¢… í†µê³„ ë¡œê·¸
        logger.info(f"""
ğŸ“Š ìŠ¤í¬ë˜í•‘ ì™„ë£Œ í†µê³„:
   ëŒ€íšŒ: {self.stats['competitions_scraped']}
   ì¢…ëª©: {self.stats['events_scraped']}
   ê²€ì¦ í†µê³¼: {self.stats['events_validated']}
   ì €ì¥ ì„±ê³µ: {self.stats['events_saved']}
   ê²€ì¦ ì˜¤ë¥˜: {self.stats['validation_errors']}
   ê²½ê³ : {self.stats['validation_warnings']}
        """)

    # ==================== ë©”ì¸ ìŠ¤í¬ë˜í•‘ ë©”ì„œë“œ ====================

    async def scrape_and_save(
        self,
        start_year: int = 2024,
        end_year: int = 2025,
        limit: Optional[int] = None,
        status_filter: str = "ì¢…ë£Œ"
    ) -> Dict[str, Any]:
        """
        ì „ì²´ ìŠ¤í¬ë˜í•‘ + ê²€ì¦ + ì €ì¥ íŒŒì´í”„ë¼ì¸

        Args:
            start_year: ì‹œì‘ ì—°ë„
            end_year: ì¢…ë£Œ ì—°ë„
            limit: ëŒ€íšŒ ìˆ˜ ì œí•œ (í…ŒìŠ¤íŠ¸ìš©)
            status_filter: ìƒíƒœ í•„í„° (ì¢…ë£Œ, ì§„í–‰ì¤‘ ë“±)

        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        # ëŒ€íšŒ ëª©ë¡ ìˆ˜ì§‘
        competitions = await self.scraper.get_all_competitions(start_year, end_year)

        if status_filter:
            competitions = [c for c in competitions if c.status == status_filter]

        if limit:
            competitions = competitions[:limit]

        logger.info(f"ğŸ“‹ ì²˜ë¦¬í•  ëŒ€íšŒ: {len(competitions)}ê°œ")

        results = []

        for i, comp in enumerate(competitions):
            logger.info(f"[{i+1}/{len(competitions)}] {comp.name}")

            try:
                result = await self._process_competition(comp)
                results.append(result)
                self.stats["competitions_scraped"] += 1
            except Exception as e:
                logger.error(f"ëŒ€íšŒ ì²˜ë¦¬ ì‹¤íŒ¨ ({comp.name}): {e}")
                results.append({
                    "competition": asdict(comp),
                    "success": False,
                    "error": str(e)
                })

        # í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        await self._collect_quality_metrics()

        return {
            "total_competitions": len(competitions),
            "results": results,
            "stats": self.stats,
        }

    async def _process_competition(self, comp: Competition) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ëŒ€íšŒ ì²˜ë¦¬ (ìŠ¤í¬ë˜í•‘ â†’ ê²€ì¦ â†’ ì €ì¥)
        """
        result = {
            "competition": asdict(comp),
            "events_processed": 0,
            "events_saved": 0,
            "errors": [],
            "warnings": [],
        }

        # 1. ëŒ€íšŒ ì €ì¥/ì¡°íšŒ
        comp_id = await self._upsert_competition(comp)
        if not comp_id:
            result["errors"].append("ëŒ€íšŒ ì €ì¥ ì‹¤íŒ¨")
            return result

        result["competition_id"] = comp_id

        # 2. ì¢…ëª© ìŠ¤í¬ë˜í•‘
        try:
            comp_data = await self.scraper.scrape_competition_full(
                comp, page_num=comp.page_num
            )
        except Exception as e:
            result["errors"].append(f"ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            return result

        # 3. ê° ì¢…ëª© ì²˜ë¦¬
        for event_data in comp_data.get("events", []):
            self.stats["events_scraped"] += 1

            try:
                event_result = await self._process_event(comp_id, event_data)

                if event_result["saved"]:
                    result["events_saved"] += 1
                    self.stats["events_saved"] += 1
                else:
                    result["errors"].extend(event_result.get("errors", []))

                result["warnings"].extend(event_result.get("warnings", []))
                result["events_processed"] += 1

            except Exception as e:
                result["errors"].append(f"ì¢…ëª© ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                self.stats["validation_errors"] += 1

        return result

    async def _process_event(
        self,
        competition_id: int,
        event_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ì¢…ëª© ì²˜ë¦¬ (ê²€ì¦ â†’ ì €ì¥)
        """
        result = {
            "event_name": event_data.get("name", "Unknown"),
            "saved": False,
            "errors": [],
            "warnings": [],
        }

        # ê²€ì¦ìš© ë°ì´í„° êµ¬ì„±
        validation_data = {
            "name": event_data.get("name", ""),
            "weapon": event_data.get("weapon", ""),
            "gender": event_data.get("gender", ""),
            "age_group": event_data.get("age_group", ""),
            "event_type": event_data.get("event_type", "ê°œì¸"),
            "competition_id": competition_id,
        }

        # ê²€ì¦ ì‹¤í–‰
        tech_result, biz_result = self.pipeline.validate_data(
            validation_data, "event"
        )

        # ê²€ì¦ ê²°ê³¼ ì²˜ë¦¬
        if tech_result.errors:
            result["errors"].extend([e.message for e in tech_result.errors])
            self.stats["validation_errors"] += len(tech_result.errors)

        if biz_result.warnings:
            result["warnings"].extend([w.message for w in biz_result.warnings])
            self.stats["validation_warnings"] += len(biz_result.warnings)

        # ê²€ì¦ í†µê³¼ ì‹œ ì €ì¥
        if tech_result.can_save and biz_result.can_save:
            self.stats["events_validated"] += 1

            try:
                event_id = await self._upsert_event(competition_id, event_data)
                if event_id:
                    result["saved"] = True
                    result["event_id"] = event_id
                else:
                    result["errors"].append("ì¢…ëª© ì €ì¥ ì‹¤íŒ¨")
            except Exception as e:
                result["errors"].append(f"ì €ì¥ ì˜¤ë¥˜: {e}")

        return result

    # ==================== ë°ì´í„°ë² ì´ìŠ¤ ì—°ì‚° ====================

    async def _upsert_competition(self, comp: Competition) -> Optional[int]:
        """ëŒ€íšŒ upsert"""
        try:
            data = {
                "comp_idx": comp.event_cd,
                "comp_name": comp.name,
                "start_date": comp.start_date.isoformat() if comp.start_date else None,
                "end_date": comp.end_date.isoformat() if comp.end_date else None,
                "status": comp.status,
                "venue": comp.location,
            }

            result = self.db.table("competitions").upsert(
                data, on_conflict="comp_idx"
            ).execute()

            if result.data:
                return result.data[0].get("id")
            return None

        except Exception as e:
            logger.error(f"ëŒ€íšŒ upsert ì˜¤ë¥˜: {e}")
            return None

    async def _upsert_event(
        self,
        competition_id: int,
        event_data: Dict[str, Any]
    ) -> Optional[int]:
        """ì¢…ëª© upsert (raw_data í¬í•¨)"""
        try:
            # raw_data êµ¬ì„±
            raw_data = {
                "pool_rounds": event_data.get("pool_rounds", []),
                "pool_total_ranking": event_data.get("pool_total_ranking", []),
                "de_bracket": event_data.get("de_bracket", {}),
                "de_matches": event_data.get("de_matches", []),
                "final_rankings": event_data.get("final_rankings", []),
            }

            data = {
                "competition_id": competition_id,
                "event_cd": event_data.get("event_cd", ""),
                "sub_event_cd": event_data.get("sub_event_cd", ""),
                "event_name": event_data.get("name", ""),
                "weapon": event_data.get("weapon", ""),
                "gender": event_data.get("gender", ""),
                "age_group": event_data.get("age_group", ""),
                "category": event_data.get("event_type", "ê°œì¸"),
                "participants_count": event_data.get("total_participants", 0),
                "raw_data": raw_data,
                "validated_at": datetime.now().isoformat(),
                "validation_version": "1.0",
            }

            result = self.db.table("events").upsert(
                data,
                on_conflict="competition_id,event_cd,sub_event_cd"
            ).execute()

            if result.data:
                return result.data[0].get("id")
            return None

        except Exception as e:
            logger.error(f"ì¢…ëª© upsert ì˜¤ë¥˜: {e}")
            return None

    # ==================== í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ====================

    async def _collect_quality_metrics(self) -> None:
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì €ì¥"""
        try:
            # ê²€ì¦ í†µê³¼ìœ¨ ê³„ì‚°
            total = self.stats["events_scraped"]
            if total > 0:
                pass_rate = self.stats["events_validated"] / total

                await self.monitor.record_metric(
                    metric_type="validation_pass_rate",
                    value=pass_rate,
                    details={
                        "total": total,
                        "passed": self.stats["events_validated"],
                        "failed": self.stats["validation_errors"],
                    }
                )

            # ì €ì¥ ì„±ê³µìœ¨ ê³„ì‚°
            if self.stats["events_validated"] > 0:
                save_rate = self.stats["events_saved"] / self.stats["events_validated"]

                await self.monitor.record_metric(
                    metric_type="save_success_rate",
                    value=save_rate,
                    details={
                        "validated": self.stats["events_validated"],
                        "saved": self.stats["events_saved"],
                    }
                )

            logger.info("ğŸ“Š í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì™„ë£Œ")

        except Exception as e:
            logger.warning(f"í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")


# ==================== CLI ====================

async def main():
    import argparse

    parser = argparse.ArgumentParser(description="íŒŒì´í”„ë¼ì¸ í†µí•© ìŠ¤í¬ë˜í¼")
    parser.add_argument("--start-year", type=int, default=2024, help="ì‹œì‘ ì—°ë„")
    parser.add_argument("--end-year", type=int, default=2025, help="ì¢…ë£Œ ì—°ë„")
    parser.add_argument("--limit", type=int, default=None, help="ëŒ€íšŒ ìˆ˜ ì œí•œ")
    parser.add_argument("--status", type=str, default="ì¢…ë£Œ", help="ìƒíƒœ í•„í„°")
    parser.add_argument("--headless", action="store_true", help="í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ")

    args = parser.parse_args()

    async with PipelineScraper(headless=args.headless) as scraper:
        result = await scraper.scrape_and_save(
            start_year=args.start_year,
            end_year=args.end_year,
            limit=args.limit,
            status_filter=args.status
        )

        logger.info(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {result['total_competitions']}ê°œ ëŒ€íšŒ")


if __name__ == "__main__":
    asyncio.run(main())
